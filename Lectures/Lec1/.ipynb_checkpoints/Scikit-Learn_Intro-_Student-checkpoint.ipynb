{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Scikit-Learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Scikit-Learn:\n",
    "\n",
    "A free library that provides tools that makes it super easy to perform data analysis. Great for getting started with learning the basics of machine learning models!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To DO:\n",
    "    *Data Representation\n",
    "    *Load Data\n",
    "    *Choose a model\n",
    "    *Intantiate Model\n",
    "    *Pick Hyperparamters\n",
    "    *Graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start off by loading one of the most famous scikit learn datasets and see what it looks like. Go ahead and take a moment to look up the Iris Dataset with scikit learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*waits a few minute* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from a Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert dataset name after import statement\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great now that we've imported the data we can load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try printing out iris and examine what information we have in the data set and explore how it's stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the iris data\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some quick terminology\n",
    "The data above just loooks like just a bunch of numbers right? Let's try to better understand what it means. \n",
    "\n",
    "    *Each row is a sample (also known as: observation, example, instance, record)\n",
    "    *Each column is a feature (also known as: predictor, attribute, independent variable, input, regressor, covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try printing out the features and samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the names of the four features called feature_names\n",
    "print(...)\n",
    "# print integers representing the species of each observation called target\n",
    "print(...)\n",
    "# print the encoding scheme for species: 0 = setosa, 1 = versicolor, 2 = virginica called target_names\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we see that each column represents a different feature, in this case sepal lenght, sepal width, petal length and petal width! We also know each row represents one example. \n",
    "\n",
    "Run the next cell to see a snippet of the code in a table that may look more familiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='iris.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember all that stuff we learned with numpy? Comes in handy again here since scikit-learn is built on top of numpy, so we can use all the stuff we learned on our data here! Let's try playing around with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the types \n",
    "print(type(iris.data))\n",
    "#print out the type of the feature_names\n",
    "print(type(iris.feature_names))\n",
    "#print out the type of the targets \n",
    "print(type(iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the shape of the data\n",
    "print(iris.data.shape)\n",
    "\n",
    "#print out the shape of the target_name\n",
    "print(iris.target_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice if we try and print out the shape of feature_names we get an error! The type is a list, therefore cannot call shape on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually when we have data we'll save it to a variable (X) and the labeled response to (Y). In this case what would we assign as X? What would we assign as Y? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fil in here how we'd load the data \n",
    "\n",
    "#Hint: X usually corresponds to the data we have \n",
    "X = iris.data\n",
    "\n",
    "#Hint: Y usually corresponds to the labels we have\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn API Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we know how to load data, let's dive a little deeper and look at some of the basics of the API. \n",
    "    1. Choose a class of model by importing the appropriate estimator class from Scikit-Learn.\n",
    "    2. Choose model hyperparameters by instantiating this class with desired values.\n",
    "    3. Arrange data into a features matrix and target vector following the discussion above.\n",
    "    4. Fit the model to your data by calling the fit() method of the model instance\n",
    "    5. Apply the Model to new data, can use predict() or transform() \n",
    "\n",
    "Lets go ahead and look at a simple example, loading a linear regression classifier with some random made up data.\n",
    "\n",
    "Don't worry if you're not familiar with linear regression, lets just note that it'll be our model of choice that helps us model points that tend to follow the pattern of a line! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Lets make some random data! \n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2 * x - 1 + rng.randn(50)\n",
    "plt.scatter(x, y);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool now we have some data to work with. Now lets go ahead and choose a model, remember how we imported a dataset before? With the same intuition let's import a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try looking at this documentation and figuring out how to import the Linear Regression Model: \n",
    "# http://scikit-learn.org/stable/supervised_learning.html\n",
    "from sklearn.linear_model import ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have decided on our model class, there are still some options open to us. Depending on the model class we are working with, we might need to answer one or more questions like the following:\n",
    "    \n",
    "    *Would we like to fit for the offset (i.e., y-intercept)?\n",
    "    *Would we like the model to be normalized?\n",
    "    *Would we like to preprocess our features to add model flexibility?\n",
    "    *What degree of regularization would we like to use in our model?\n",
    "    *How many model components would we like to use?\n",
    "\n",
    "These are examples of the important choices that must be made once the model class is selected. These choices are often represented as hyperparameters, or parameters that must be set before the model is fit to data. \n",
    "\n",
    "Throughout the course of this decal you're going to learn more about each of these questions and how to answer them! For now don't worry too much we're just showing you an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our target variable y is already in the correct form (a length-n_samples array). Think about how iris.target looked? Same idea! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although think back to the Iris dataset, every example was its own row. Currently our X data is just one long row. We'll need to fix this and make the data x a matrix of [n_samples, n_features]. \n",
    "\n",
    "In this case we have 50 samples, and 1 feature so we'll need a matrix of shape (50, 1)! Can you figure out how to reshape the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "#Hint: Look up how to transpose a 1-D Matrix\n",
    "X = x[...]\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Now lets apply the model to our data, we can do this by calling model.fit() with our paramters x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in your paramters here! \n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, and yep it's that easy! Now let's take a look at what the model actually fit to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two parameters represent the slope and intercept of the simple linear fit to the data. Comparing to the data definition, we see that they are very close to the input slope of 2 and intercept of -1.\n",
    "\n",
    "Now lets plot these results and see what it looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## np.linspace returns us nice evely distrubuted values \n",
    "xfit = np.linspace(-1, 11)\n",
    "## Rember what np.newaxis does? \n",
    "Xfit = xfit[:, np.newaxis]\n",
    "yfit = model.predict(Xfit)\n",
    "\n",
    "#Let's plot this bad boy! \n",
    "plt.scatter(x, y)\n",
    "plt.plot(xfit, yfit);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now let's take the basics we just learned and see if we can classify digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying MNIST Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST digit data set is a very famous and widely used dataset! Lucky for us Scikit learn has already preformatted the data, so it's super easy to use! Let's go ahead and load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What do you think X would be based on our last example?  \n",
    "X = ...\n",
    "print(X.shape)\n",
    "y = ...\n",
    "print(y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets actually visualize what this data looks like, run the cell below! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool,  Now that we have some data! Unlike before though, this data cannot be directly plotted on a 2D graph. It's pretty hard to visualize this data on a 64 dimensional paramter space so lets use a technique called Manifold Learning. Don't worry too much about this, the gist is that we can we can reduce the data to a 2D space to better visuaize it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "iso = Isomap(n_components=2)\n",
    "iso.fit(digits.data)\n",
    "data_projected = iso.transform(digits.data)\n",
    "data_projected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! Now our data is 2D, coolio let's plot this bad boy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_projected[:, 0], data_projected[:, 1], c=digits.target,\n",
    "            edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('spectral', 10))\n",
    "plt.colorbar(label='digit label', ticks=range(10))\n",
    "plt.clim(-0.5, 9.5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wowza what a world of color. Now what does this mean? Lets compare two digs, zeros and ones!\n",
    "\n",
    "Zeros (in black) and ones (in purple) have very little overlap in parameter space. Intuitively, this makes sense: a zero is empty in the middle of the image, while a one will generally have ink in the middle. \n",
    "\n",
    "Now thik about 5 (bright green) and 6 (lime colored green). Their data points seem to be really close! Why is this? Think about a 5 and a 6, they definitely share some overlap. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now that we've better visualized our data lets actually clasify these digits. \n",
    "\n",
    "We're going to split up our data. We'll use some of it to train a model and some of it to test the accurarcy of the model. Again don't worry too much about these concepts they'll be covered way more in depth throughout the course of this decal! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose a model. For this we're going ot choose a Gaussian naive Bayes model with model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "#Think about what X and Y we would use here as our paramters! \n",
    "model.fit(..., ...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model.predict method to see what values our model predict for the data. We'll use the X test data we set aside a few cells before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure we predict on data the model hasn't seen before! \n",
    "\n",
    "y_model = model.predict(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now lets use y_model and compare it to the test data we set aside and see how our model performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "##Let's compare the he actual y test values to the results of our model \n",
    "accuracy_score(ytest, y_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too shabby of results for just a few lines of code! One fun thing we can use to visualize results are a confusion matrix. This will tell us which digits were misclassified the most in a nice visually pleasing chart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(ytest, y_model)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cool! Now we can see where our model messes up. We can see for example, ones and twos are sometimes predicted as eights! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Congrats! You made it!\n",
    "It's okay if you don't understand everything that happend in this lab! What we wanted was for everyone to get familiar with using a library and the process of of loading data, visualizing that data, picking a model and actually applying the model! "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
